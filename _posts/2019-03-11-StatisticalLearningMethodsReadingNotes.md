---
title: "《统计学习方法》的读书笔记"
excerpt: "“小蓝书” 的读书笔记，记录自己认为的重点内容。"
classes: wide
categories:
- Algorithm
tags:
- Machine Learning
- Statistics Learning
- Data Science
create_at: 2019-03-11
last_modified_at: 2019-03-20
toc: true
toc_label: "文章提纲"
toc_icon: "book-reader"
toc_sticky: true
---

# 全书总评

* 书本印刷质量：4 星。印刷清楚，排版合适，错误很少。
* 著作编写质量：4 星。自学机器学习的必备。
  * 优点
    * 全书一直围绕着统计学习中的有监督学习描述，内容不深，基本算法都有所介绍；
    * 内容的组织是从抽象到具体的思维模式，比国外的教材易于理解；
    * 是自学统计学习和机器学习的推荐用书。
  * 缺点
    * 基础部分讲解缺少理论，学完后无法理解，不利用学以致用。例如：感知器的损失函数，应该是统计学习的核心思想，那么损失函数在整个算法中的位置，以及如何选择损失函数都需要说明清楚，才能够指导后面各种其他机器学习方法的理解。
    * 使用的方法没有导入的原因和出处，学习过程中会产生比较大的跳跃感，延续性不足。例如：随机梯度下降法，只是说明用于神经网络的优化需要用随机梯度下降，而实际上随机梯度下降是为了满足在线学习的需要，如果是批量学习可以直接使用梯度学习算法实现。
  * 总结：瑕不掩瑜，建议结合 “西瓜书” \[周志华，2018] 一起看。
* 笔记目的：记录重点，方便回忆。

# C01. 统计学习方法概论

* 这一章都是概念和结论，如果读者能够透过概念就明白里面实际操作的内容，那就可以快速浏览此书，否则准备纸和笔认真精读方能收获。
* 后面的各章内容相对独立，读者既可以连续学习，也可以仅选择自己感兴趣的内容。

## 统计学习

### 统计学习导言

* 统计学习 (statistical learning): 计算机基于数据构建概率统计模型，并运用模型对数据进行预测与分析的一门学科。
  * 因此统计学习也称为统计机器学习 (statistical machine learning).
* 统计学习的主要特点
  * 理论基础
    * 数学基础：微积分、线性代数、概率论、统计学、计算理论、最优化理论
    * 其他基础：信息论、计算机科学及应用相关的科学等多个领域的交叉学科
    * 在发展中形成自己独立的理论体系与方法论。
  * 应用基础：计算机及网络；
  * 研究对象：数据，是数据驱动的学科；
  * 研究目的：对数据进行分类和预测；
  * 研究手段：通过统计学习方法构建模型，并应用模型进行分类和预测；

### 统计学习的对象

* 统计学习的对象是数据 (data)
  * 从数据出发，提取数据的 “特征” ，抽象出数据的 “模型” ，发现数据中的 “知识” ，又回到对数据的 “分类” 与 “预测” 中。
  * 数据的基本假设：同类数据具有一定的统计规律性，所以可以用概率统计方法加以处理。
  * 数据分类有 "连续型" 和 "离散型" 两种，本书主要关注的是 "离散型" 数据。

### 统计学习的目的

* 模型：学习什么样的模型
* 策略：如何学习模型 → 使模型能够对数据进行准确地分类和预测
* 算法：如何提高模型的学习效率

### 统计学习的方法

* **统计学习的方法分类**
  * **有监督学习 (supervised learning)** （全书重点）
    * 从给定的、有限的、用于学习的训练数据 (training data) 集合出发；
      * 假设数据是独立同分布产生的；
    * 假设要学习的模型属于某个函数的集合，称为假设空间 (hypothesis space);
    * 基于某个评价标准 (evaluation criterion), 从假设空间中选取一个最优的模型
      * 使模型在给定的评价准则下，对已知训练数据及未知测试数据 (test data) 都有最优的预测；
    * 最优模型的选取都由算法实现。
  * 无监督学习 (unsupervised learning):
  * 半监督学习 (semi-supervised learning):
  * 强化学习 (reinforcement learning):
* 统计学习方法的三个要素
  * 模型 (model): 模型的假设空间；
  * 策略 (strategy): 模型选择的准则；
  * 算法 (algorithm): 模型学习的算法。
* 实现统计学习方法的步骤
  * 得到一个有限的、用于训练的数据集合；
  * 模型的集合：确定包含所有可能的模型的假设空间；
  * 学习的策略：确定模型选择的准则；
  * 学习的算法：确定求解最优模型的算法；
  * 通过学习的方式选择出最优模型；
  * 利用学习的最优模型对新数据进行分类或预测。
* 统计学习中的有监督学习根据 "解决的问题" 主要包括
  * **分类问题**：判别模型，处理离散数据
  * **预测问题**：回归模型，处理连续数据
  * 标注问题：既是分类问题的推广，又是预测问题的简化。

### 统计学习的研究

* 统计学习方法 (statistical learning method): 开发新的学习方法；
* 统计学习理论 (statistical learning theory): 探求统计学习方法的有效性与效率，以及统计学习的基本理论问题；
* 统计学习应用 (application of statistical learning): 将统计学习方法应用到实际问题中去，解决实际问题。

### 统计学习的重要性

* 是处理海量数据的有效方法；
* 是计算机智能化的有效手段；
* 是计算机科学发展的重要组成。

## **监督学习**

* 监督学习的任务：是学习一个模型，使模型能够对任意给定的输入，及其相应的输出做出一个好的预测

### 基本概念

* 输入空间：输入数据所有可能取值的集合；集合中元素的个数可以有限，也可以是整个空间；
* 输出空间：输出数据所有可能取值的集合；集合中元素的个数可以有限，也可以是整个空间；
* 假设空间：由输入空间到输出空间的映射的集合，即可供选择的模型构成的空间；
* 特征空间：所有特征向量存在的空间。
  * 每个具体的输入是一个实例 (instance), 通常由特征向量 (feature vector) 表示。
* 统计学习中的有监督学习根据 "输入变量" 和 "输出变量" 的不同主要包括
  * 分类问题：输出变量为有限个离散变量的预测问题；
  * 回归问题：输入变量与输出变量均为连续变量；
  * 标注问题：输入变量与输出变量均为变量序列的预测问题；
* 联合概率分布：输入变量与输出变量遵循联合分布；

### 问题的形式化描述

* 在学习过程中，学习系统（也就是学习算法）试图通过给定的训练数据集合中的样本带来的信息来学习得到模型。

## 统计学习三个要素

* 统计学习方法 = 模型 + 策略 + 算法

### 模型

* 主要问题：学习什么样的模型？
* 模型的假设空间：包含所有可能的条件概率分布或决策函数，即由一个参数向量决定的函数族，也称为参数空间 (parameter space)。
* 模型分类
  * 非概率模型：由决策函数表示的模型；
  * 概率模型：由条件概率表示的模型；

### 策略

* 主要问题：按照什么样的准则，学习得到最优的模型，或者从假设空间中选择最优的模型。
* 基本概念
  * 损失函数 (loss function) 或代价函数 (cost function): 度量模型一次预测的好坏；
  * 风险函数 (risk function) 或期望损失 (expected loss): 度量平均意义下模型预测的好坏。
  * 经验风险 (empirical risk) 或经验损失 (empirical loss): 表示模型与训练数据的破例程度，即模型训练样本集的平均损失，当样本容量趋于无穷时，经验风险逼近期望风险；
  * 结构风险 (structural risk): 表示模型先验知识，例如：模型复杂度的正则化项 (regularizer) 或惩罚项 (penalty term)。
* 常用的损失函数
  * 0-1 损失函数
  * 平方损失函数
  * 绝对值损失函数
  * 对数损失函数或对数似然损失函数
* 学习目标
  * 理想状态：就是选择期望风险或期望损失最小的模型，希望可以提供无限的数据训练；
  * 现实状态：就是选择经验风险或经验损失最小的模型，因为只能提供有限的数据训练；
* 经验风险矫正：当样本容量过小时，容易出现 "过拟合" 问题，所以需要对经验风险进行矫正，经验风险最小化 + 结构风险最小化
  * 经验风险最小化 (empirical risk minimization, ERM): 极大似然估计
  * 结构风险最小化 (structural risk minimization, SRM): 最大后验估计

### 算法

* 统计学习是基于训练数据集，根据学习策略，从假设空间中选择最优模型，最后需要考虑用什么样的计算方法求解最优模型。
* **算法** 即计算方法。统计学习的算法就转化为求解最优化问题的算法。
  * 有显式的解析解的最优化问题；
  * 无显式的解析解的最优化问题，需要用数值计算的方法求解。
    * 如何保证找到全局最优解；
    * 如何保证求解的过程高效。

## 模型的评估与选择

* 1.4~1.7, 与模型选择有关的问题。
* 1.8~1.10, 与模型应用有关的问题。

### 模型评估

* 学习方法评估的标准
  * 基于损失函数的模型的训练误差 (training error): 用来评估一个学习问题是否容易学习
  * 基于损失函数的模型的测试误差 (test error): 用来评估一个模型是否具备更有效的预测
* 泛化能力 (generalization ability): 学习方法对未知数据的预测能力

### 模型选择

* 过拟合 (over-fitting): 学习时选择的模型所包含的参数过多，以至于模型对已知数据预测较好，未知数据预测较差的问题
* 模型选择的常用方法
  * 正则化
  * 交叉验证

## 正则化与交叉验证

### 正则化

* 正则化 (regularization): 结构风险最小化策略的实现，是在经验风险上加一个正则化项或惩罚项。
  * 正则化项一般是模型复杂度的单调递增函数。
    * 复杂度定义可以参考 Kolmogorov 复杂性理论 (complexity theory) \[Haykin, 2011] P48
  * Occam 剃刀原理：应用于模型选择时符合正则化的想法，即所有能够解释数据的模型中，复杂度越小越好。
  * Bayes 估计：正则化项对应于模型的先验概率。数据较少时先验概率就可以抑制数据中噪声的干扰，防止出现过拟合问题。数据很多时，先验概率就让位于数据对模型的解释。
  * 正则化是优化学习算法，调整目标函数，增加先验知识的重要手段，是机器学习的核心之一。
    * 简单了解：\[周志华，2018] P133
    * 深入理解：\[Haykin, 2011] C07

### 交叉验证

* 交叉验证 (cross validation)
  * 在数据充足时，随机地将数据切分成三个部分：训练集、验证集和测试集。
    * 选择对验证集有最小预测误差的模型。
  * 训练集 (training set): 用来训练模型；
  * 验证集 (validation set): 用来选择模型；
  * 测试集 (test set): 用来评估模型。
* 交叉验证的常用方法
  * 简单交叉验证：随机地将数据分成两个部分，70% 的数据为训练集，30% 的数据为测试集，选择测试误差最小的模型；
  * S 折交叉验证
    * 随机地将数据分成 S 个互不相交的大小相同的部分
    * 然后利用 S-1 个部分的数据训练，1 个子集测试模型，
    * 再将这一个过程对所有可能的选择重复进行，
    * 最后选择 S 次评测中平均测试误差最小的模型。
  * 留一交叉验证：当 S=N 时采用的 S 折交叉验证，适用于数据极度缺乏的情况下。(N 为给定数据集的容量）

## 泛化能力

### 泛化误差

* 泛化能力 (generalization ability): 是指学习方法学习到的模型对未知数据的预测能力
* 泛化误差 (generalization error): 是指学到的模型对未知数据预测产生的误差，反映了学习方法的泛化能力。

### 泛化误差的上界

* 泛化误差的上界 (generalization error bound): 泛化误差的概率上界，通过比较两种学习方法的泛化误差概率上界来确定优劣
* 泛化误差上界的性质
  * 是样本容量的函数，当样本容量增加时，泛化上界趋向于 0;
  * 是假设空间的函数，当假设空间容量增加时，泛化误差上界就会变大，表示模型就更加难学。
* _泛化误差上界定理及证明_（建议放弃）

## 生成模型与判别模型

* 生成模型 (generative model): 模型表示了给定输入 X 产生输出 Y 的生成关系。
  * 特点
    * 还原出联合概率分布；
    * 学习收敛速度快；
    * 样本容量增加时，能够更好地逼近真实模型；
    * 存在隐变量时，仍然可以使用。
  * 应用：朴素 Bayes 方法和隐马尔可夫模型 (Hidden Markov Model, HMM);
  * 注：生成模型是比较难理解的概念，HMM 是理解生成模型比较好的途径，如果对 HMM 感兴趣可以参考
    * 简单了解：\[周志华，2018] P320
    * 深入理解：\[Rabiner, 1989]
* 判别模型 (discriminative model): 由数据直接学习决策函数或者条件概率分布作为预测的模型
  * 特点
    * 直接学习得到条件概率分布或者决策函数；
    * 直接面对预测，学习的准确率更高；
    * 基于参数是直接学习得到的，因此可以对数据进行各种程度上的抽象、定义和使用特征，简化学习问题。
  * 应用：k 近邻法、感知机、决策树、Logistic 回归模型、最大熵模型、支持向量机、提升方法和条件随机场等

## 分类问题

* 分类器 (classifier): 监督学习从数据中学习得到的分类模型或分类决策函数。
* 分类 (classification): 利用分类器对新输入的数据进行输出的预测。
* 解决分类问题的两个过程
  * 学习过程：根据已知的训练数据集利用有效的“学习方法”得到一个分类器；
  * 分类过程：利用学习得到的分类器对新输入的实例进行分类。
* 评价分类器性能的指标：分类准确率 (accuracy), 即对于给定的测试数据集，分类器正确分类的样本数与总样本数之比。
  * 二类分类问题常用的评价指标：精确率 (precision) 与召回率 (recall)。
* 解决分类问题的常用方法：k 近邻法、感知机、朴素 Bayes 法，决策树、决策列表、Logistc 回归模型、支持向量机、提升方法等

## 标注问题

* 标注问题：是分类问题的推广，也是更复杂的结构预测问题的简单形式。
  * 输入是一个观测序列；
  * 输出是一个标记序列或状态序列。
  * 目标是通过学习得到能够对观测序列给出标记序列作为预测的模型。
* 解决标注问题的两个过程：学习过程 和 标注过程
* 评价标注问题的指标：准确率、精确率和召回率。
* 解决标注问题的常用方法：隐 Markov 模型和条件随机场。

## 回归问题

* 回归 (regression): 用于预测输入变量（自变量）和输出变量（因变量）之间的关系。
* 回归模型：表示从输入变量到输出变量之间的映射关系的函数。
  * 等价于：函数拟合。
* 解决回归问题的两个过程：学习过程和预测过程。
* 回归问题的分类
  * 按输入变量的个数：一元回归和多元回归；
  * 按输入变量和输出变量之间的关系：线性回归和非线性回归。
* 回归学习最常用的损失函数：平方损失函数，求解平方损失函数可以用最小二乘法。

# C02. 感知机

* **模型**
  * 感知机，是根据输入实例的特征向量对其进行二类分类的线性分类模型，属于判别模型；
  * 模型参数包括：权值或权值向量，偏置。
  * 模型对应于输入空间（特征空间）中的分离超平面；
* **策略**
  * 假设：感知机学习的训练数据集是线性可分的；
  * 目标：求得一个能够将训练集正实例点和负实例点完全正确分开的分离超平面；
  * 策略：即定义（经验）损失函数，并将损失函数极小化；
    * 损失函数定义为：误分类点的总数，不易优化；
    * 损失函数定义为：误分类到分离超平面的总距离；
* **算法**
  * 感知机学习算法是基于误差 - 修正的学习思想，是由误分类驱动的；
  * 学习算法的优化方法
    * 批量学习可以基于进行优化
      * 一阶：最速下降法或梯度下降法；
      * 二阶：牛顿法、共轭梯度法等等
    * 在线学习：基于随机梯度下降法的对损失函数进行最优化 \[Goodfellow, 2017] P95, P180
      * 原始形式：算法简单且易于实现。先任意选取一个超平面，然后随机选择一个误分类点使其用梯度下降法极小化目标函数
        * _例 2.1_（比较简单，可以了解）
        * _定理 2.1_（过于简略，可以跳过）
      * _对偶形式_ （没看出与原始形式有何区别，也没从别的书上看到过这种说明方式，建议跳过）
  * 当训练数据集线性可分时，感知机学习算法是收敛的，且有无穷多个解。
* **学习总结**
  * 感知机是神经网络的基础，本章只有单个神经元模型，详细学习参考 \[Haykin, 2011]
  * 神经网络是深度学习的基础，需要了解深度学习参考 \[Goodfellow, 2017]
  * 距离度量是几何的概念，只想了解基础可参考 \[Duda, 2003] P154
  * 学习算法的优化是最优化理论，只想了解基本优化方法可参考 \[Hyvarinen, 2007] P42

# C03.  **k** _近邻法_

* **k** 近邻法 (k-nearest neighbor, k-NN) 是一个基本且简单的方法，用于分类与回归。
  * 输入为实例的特征向量，对应于特征空间的点；
  * 输出为实例的类别，可以取多个类。
* 基本思想
  * 假设给定一个训练数据集，其中的实例类别已经确定；
  * 对新输入的实例分类时，根据其 k 个最近邻的训练实例的类别，通过多数表决等方式进行预测。
  * 不具有显式的学习过程。
  * 实际上利用训练数据集对特征向量空间进行切分，并作为其分类的 "模型"。
* **k** 近邻的模型
  * 对应于基于训练数据集对特征空间的一个划分。
  * 当训练集、距离度量、k 值及分类决策规则确定后，输入实例所属类别也唯一确定。
* **k** 近邻法的三个要素
  * **学习准则**：距离度量，常用欧氏距离；（距离定义）\[Duda, 2003]
  * k 值的选择：反映了近似误差与估计误差之间的权衡。
    * k 值越大时，近似误差会增大，估计误差会减小，模型也越简单；
    * k 值越小时，近似误差会减少，估计误差会增大，模型也越复杂。
    * 可以用交叉验证的方式选择最优 k 值。
  * 分类决策规则：多数表决规则 (marjority voting rule), 等价于 经验风险最小化。
* **k** _近邻法的实现基于 kd 树_。（了解即可，实际应用中大多使用的是已经成熟的软件包）
  * kd 树是一种便于对 k 维空间中的数据进行快速检索的数据结构；
  * kd 树是二叉树，表示对 k 维空间的一个划分；
  * kd 树的每个圣战对应于 k 维空间划分中的一个超矩形区域；
  * 利用 kd 树可以省去对大部分数据点的搜索，从而减少搜索的计算量。
* **学习总结**
  * 了解即可，因为面对高维问题效果很差，需要考虑降维操作。\[周志华，2018] P225

# C04. 朴素 Bayes 法

* 朴素 (naive) Bayes 法：是基于 Bayes 定理与所有特征都遵循条件独立性假设的分类方法。
  * 朴素 Bayes 法是 Bayes 分类法的一种，遵循 Bayes 定理建模。\[Mitchell, 2003] P112
  * 朴素 Bayes 法基于的条件独立性假设是说用于分类的特征在类别确定的条件下都是条件独立的。简化了计算复杂度，牺牲了分类准确率。
  * 朴素 Bayes 法是生成学习方法。
    * 先验概率分布；
    * 条件概率分布；
    * 后验概率分布。后验概率最大化准则等价于期望风险最小化准则。
    * 目标：由训练数据学习联合概率分布；
  * 朴素 Bayes 方法的**概率参数估计**方法：
    * **极大似然估计** : 概率估计常用的方法；
    * **Bayes 估计** : 重点在于了解与极大似然估计的差别，才可以正确使用。
* **学习总结**
  * 虽然不需要自己估计参数，但是对估计的理解很重要，书中的描述过于简单，具体内容请参考 \[Duda, 2003] P67

# C05. 决策树 (decision tree)

* **决策树模型**
  * 决策树是一种基本方法，用于分类与回归。
    * 本章主要讨论的是分类决策树。
  * 分类决策树模型
    * 定义：是基于特征对实例进行分类的树形结构。
    * 模型的组成结构
      * 结点 (node)
        * 内部结点 (internal node)
        * 叶结点 (leaf node)
      * 有向边 (directed edge)
    * 分类决策树可以转换成一个 if-then 规则的集合；
      * 决策树的根结点到叶结点的每一条路径构建一条规则；
      * 路径上内部结点的特征对应着规则的条件，而叶结点的类对应着规则的结论。
      * 重要的性质：互斥并且完备，即全覆盖。
        * 覆盖是指实例的特征与路径上的特征一致或实例满足规则的条件。
    * 也可以看作是定义在特征空间与类空间上的条件概率分布。
      * 这个条件概率分布定义在特征空间的一个划分上，
      * 将特征空间划分为互不相交的单元或区域，
      * 并在每个单元定义一个类的概率分布就构成了一个条件概率分布。
      * 决策树分类时，将结点的实例分到条件概率大的类中。
    * 主要优点：可读性强，分类速度快。
* 决策树学习
  * 学习目的
    * 根据给定的训练数据集，构建一个与训练数据拟合很好，并且复杂度小的决策树，使之能够对实例进行正确的分类。
    * 决策树与训练数据的矛盾较小，同时还具有较好的泛化能力。
    * 也可以看作由训练数据集估计条件概率模型
      * 模型对训练数据拟合的效果很好；
      * 模型对未知数据有很好的预测。
    * 从所有可能的决策树中选取最优决策树是 NP 完全问题；
      * 现实中采用启发式方法学习次优的决策树。
  * **学习准则**：损失函数最小化。
    * 损失函数是一种正则化的极大似然函数
  * **学习算法**
    * 递归地选择最优特征，并根据该特征对训练数据进行分割，使之对各个数据集有一个最好的分类的过程。
* 决策树的学习算法包括 3 个部分
  * 特征选择
    * 特征选择的目的在于选取对训练数据能够分类的特征，提高决策树学习的效率；
    * 特征选择的关键是其准则
      * 样本集合 D 对特征 A 的**信息增益** 最大
        * 信息增益定义为集合 D 的经验熵与特征 A 在给定条件下 D 的经验条件熵之差。
          * 熵：表示随机变量不确定性的度量。也称为经验熵。
          * 条件熵：定义为 X 给定条件下 Y 的条件概率分布的熵对 X 的数学期望。也称为经验条件熵。
        * 信息增益表示得知特征 X 的信息而使得类 Y 的信息的不确定性减少的程度。
        * 信息增益等价于训练数据集中类与特征的互信息。
        * 信息增益依赖于特征，信息增益大的特征具有更强的分类能力。
      * 样本集合 D 对特征 A 的**信息增益比** 最大
        * 为了避免信息增益对取值较多的特征的偏重，使用信息增益比来代替；
        * 信息增益比：特征 A 对训练数据集 D 的信息增益与训练数据集 D 关于特征 A 的值的熵之比。
      * 样本集合 D 的**基尼指数** 最小
  * 树的生成
    * 计算指标，再根据准则选取最优切分点，从根结点开发，递归地产生决策树。
    * 通过不断地选择局部最优的特征，得到可能是全局次优的结果。
  * 树的剪枝：将已经生成的树进行简化的过程。
    * 目的：由于生成的决策树存在过拟合问题，需要对它进行剪枝，以简化学到的决策树。
    * 剪枝的准则：极小化决策树整体的损失函数或代价函数，等价于正则化的极大似然估计。
    * 剪枝的分类
      * 预剪枝：也叫分支停止准则。在决策树生成过程中，对每个结点在划分前先进行估计，若当前结点的划分不能带来决策树泛化性能提升，则停止划分并将当前结点标记为叶结点；
      * 后剪枝：先从训练集生成一棵完整的决策树，然后自底向上地对非叶结点进行考察，若将该结点对应的子树替换为叶结点能带来决策树泛化性能提升，则将该子树替换为叶结点。
  * 常用的学习算法
    * ID3: 在决策树的各个结点上应用信息增益准则选择特征，递归地构建决策树。相当于用极大似然法进行概率模型的选择。
    * C4.5: 在决策树的各个结点上应用信息增益比准则选择特征，递归地构建决策树。
    * CART: 既可用于分类，也可用于回归。
      * 等价于递归地二分每个特征，将输入空间即特征空间划分为有限个单元，并在这些单元上确定预测的概率分布，也就是在输入给定的条件下输出的条件概率分布。
      * CART 算法的两个过程
        * 决策树生成：基于训练数据集生成决策树，要尽量大；
          * 回归树生成
            * 用平方误差最小准则求解每个单元上的最优输出值。
            * 回归树通常称为最小二乘回归树。
          * 分类树生成
            * 用基尼指数选择最优特征，并决定该特征的最优二值切分点。
            * 算法停止计算的条件
              * 结点中的样本个数小于预定阈值；
              * 样本集的基尼小于预定阈值；
        * 决策树剪枝
          * 用验证数据集对已经生成的树进行剪枝，剪枝的标准为损失函数最小，基于标准选择最优子树。
          * 可以通过交叉验证法对用于验证的独立数据集上的子树序列进行测试，从中选择最优子树。
        * \[Duda, 2003] P320, CART 作为通用的框架，定义了 6 个问题
* 决策树的预测
  * 对新的数据，利用决策树模型进行分类。
* **学习总结**
  * 算法 (5.1, 5.2, 5.6) + 例题 ( 5.1, 5.2, 5.3, 5.4 ) 通过算法和例题可以增强理解；
  * 损失函数的定义可以进一步参考 "不纯度" 指标 \[Duda, 2003] P320, 或 "纯度" 指标 \[周志华，2018] P75
    * "不纯度" 指标是求极小值，可以跟梯度下降法等最优化理论结合。

# C06. Logistic 回归与最大熵模型

* 模型
  * Logistic 回归模型，也称为对数几率回归模型，输入是的线性函数，输出的是对数几率模型
    * 基于 Logistic 分布建立的，表示条件概率的分类模型
      * Logistic 分布是 Sigmoid 函数，**定义 6.1**
    * 对数几率 (log odds) 或 logit 函数
      * 一个事件的几率 (odds) 是指该事件发生的概率与该事件不发生的概率的比值。
    * 二项 Logistic 回归模型是二类分类模型，**定义 6.2**
    * 多项 Logistic 回归模型是多类分类模型
    * 模型参数估计
      * 极大似然估计法
  * 最大熵模型
    * 基于最大熵原理推导的，表示条件概率分布的分类模型，可以用于二类或多类分类。
      * 最大熵原理认为，在所有可能的概率模型（分布）的集合中，熵最大的模型是最好的模型。
      * **准则**：最大熵原理是概率模型学习或估计的一个准则。
    * 最大熵模型的学习
      * 最大熵模型的学习过程就是求解最大熵模型的过程
      * 最大熵模型的学习可以形式化为有约束的最优化问题（对偶问题）
        * 拉格朗日乘子参考附录 C
    * **例 6.1, 6.2** 方便理解最大熵模型的算法原理。
* **算法**
  * 学习采用极大似然估计或者正则化极大似然估计
    * 形式化为无约束最优化问题
  * 求解无约束最优化问题的算法
    * 迭代尺度法
    * 梯度下降法
    * 拟牛顿法
* **学习总结**
  * Logistic 模型与最大熵模型都属于对数线性模型。\[周志华，2018] C03
  * 极大似然估计：书里写的比较简单，没有原理性的说明，推荐（\[周志华，2018] P149, \[Duda, 2003] P67）
  * 模型学习的最优化算法：书里写的不太好理解。各种机器学习和模式识别的书里面都有介绍，推荐（\[周志华，2018] P403, \[Hagan, 2006] C09）

# C07. 支持向量机

* 支持向量机（Support Vector Machine， SVM）是一种二类分类模型。
  * 基本模型是定义在特征空间上的间隔最大的线性分类器
  * 基本概念
    * 支持向量决定了最优分享超平面
      * 最终判别时，只需要很少的“重要”训练样本，大幅减少计算量。
    * 间隔（看懂数学公式就可以理解间隔，判别在数据的维度上又增加了一个维度）
  * 与其他模型的比较
    * 与感知机的区别：间隔最大化产生最优超平面；
    * 与线性模型的区别：使用核技巧成为非线性分类器。
  * 分类
    * 线性可分支持向量机，硬间隔支持向量机。
    * 线性支持向量机，软间隔支持向量机，是最基本的支持向量机。
    * 非线性支持向量机
  * 学习
    * 学习在特征空间进行的
    * 学习策略是间隔最大化
* 线性可分支持向量机 (linear support vector machine in linearly separable case)
  * 条件：训练数据线性可分；
  * 学习策略：硬间隔最大化
    * 求解能够正确划分训练数据集并且几何间隔最大的分离超平面
    * 对训练数据集找到几何间隔最大的超平面意味着以充分大的确信度对训练数据进行分类
    * 这样的超平面对未知原新实例有很好的分类预测能力
  * 解的特征
    * 最优解存在且唯一；（_唯一性证明_，可以略过）
    * 支持向量由位于间隔边界上的实例点组成；
* 线性支持向量机 (linear support vector machine)
  * 条件
    * 训练数据近似线性可分；
    * 训练数据中存在一些特异点 (outlier)
  * 学习策略：软间隔最大化
    * 惩罚参数 C * 替代损失函数 f，表示误判的代价；
      * hinge 损失（合页损失函数）：保持了稀疏性
      * 指数损失
      * 对率损失：相似于对率回归模型
    * 目标是使间隔尽量大，误分类点尽量少。
  * 解的特征
    * 权值唯一，偏置不唯一；
    * 支持向量由位于间隔边界上的实例点、间隔边界与分离超平面之间的实例点、分离超平面误分一侧的实例点组成；
    * 最优分享超平面由支持向量完全决定。
* 非线性支持向量机 (non-linear support vector machine)
  * 基本概念
    * 线性空间：满足线性性质的空间
    * 距离：是一种度量
      * 距离的集合 ⟶ 度量空间 + 线性结构 ⟶ 线性度量空间
    * 范数：表示某点到空间零点的距离
      * 范数的集合 ⟶ 赋范空间 + 线性结构 ⟶ 线性赋范空间 
    * 内积空间：添加了内积运算的线性赋范空间
      * 线性赋范空间 + 内积运算 ⟶ 内积空间
    * 欧氏空间：有限维的内积空间
    * 希尔伯特空间：内积空间满足完备性，即扩展到无限维
      * 内积空间 + 完备性 ⟶ 希尔伯特空间
    * 巴拿赫空间：赋范空间满足完备性
      * 赋范空间 + 完备性 ⟶ 巴拿赫空间
  * 条件：
    * 训练数据非线性可分；
    * 通过非线性变换（核函数）将输入空间（欧氏空间或离散集合）转化为某个高维特征空间（希尔伯特空间）中的线性可分；
    * 在高维特征空间中学习线性支持向量机。
  * 学习策略：核技巧 + 软间隔最大化
* 最大间隔法
  * 间隔概念
    * 函数间隔：表示分类的正确性及确信度
    * 几何间隔：规范化后的函数间隔，实例点到超平面的带符号的距离
  * 分类
    * 硬间隔最大化 (hard margin maximization)
    * 软间隔最大化 (soft margin maximization)
  * 间隔最大化的形式化
    * 求解凸二次规划问题
      * 最优化算法
    * 正则化的合页损失函数的最小化问题
  * 求解过程
    * 原始最优化问题应用拉格朗日对偶性；
    * 通过求解对偶问题得到原始问题的最优解。
    * 中间也可以根据需要自然引入核函数。
* 核技巧 (kernel method) 通用的机器学习方法
  * 应用条件
    * 非线性可分训练数据可以变换到线性可分特征空间；
    * 目标函数中的内积可以使用非线性函数的内积替换；
    * 非线性函数的内积可以使用核函数替换；
    * 核函数使非线性问题可解。
  * 常用的核函数
    * 线性核：对应于线性可分问题
    * 多项式核函数
    * 高斯核函数
    * Sigmoid 核函数
    * 函数组合得到的核函数
      * 两个核函数的线性组合仍然是核函数，k1(x,z) 和 k2(x,z) 是核函数，c1 和 c2 是任意正数，则 k(x,z)=c1k1(x,z)+c2k2(x,z) 也是核函数。
      * 两个核函数的直积仍然是核函数，k1(x,z) 和 k2(x,z) 是核函数，则 k(x,z)=k1(x,z)k2(x,z) 也是核函数。
      * k1(x,z) 是核函数，g(z) 是任意函数，则 k(x,z)=g(z)k1(x,z)g(z) 也是核函数。
* SMO 算法
  * 支持向量机学习的启发式快速算法
  * 流程
    * 将原二次规划问题分解为只有两个变量的二次规划子问题；
      * 第一个变量是违反 KKT 条件最严重的变量；
      * 第二个变量是使目标函数增长最快的变量；
      * 目标是使两个变量所对应样本之间的间隔最大。
    * 对子问题进行解析分解；
    * 直到所有变量满足 KKT 条件为止。
* **学习总结**
  * 支持向量机与神经网络是两大重要的机器学习算法；
  * 结合周老师的书一起看，对于理解支持向量机会有较大帮助。\[周志华，2018] C06
  * 深入了解支持向量机的理论分析。\[Haykin, 2011] C06

# C08. 提升方法（集成学习）

提升方法是一种统计学习方法，也是一种提升模型学习能力和泛化能力的方法，还是一种组合学习（集成学习）的方法，是统计学习中最有效的方法之一。

* 为什么要将各种学习方法组合起来？
  * 强可学习方法与弱可学习方法的等价性；
  * 将各种弱可学习方法组合起来就可以提升 (boost) 为强可学习方法
* 如何将各种学习方法组合起来？
  * AdaBoost 算法
    * 是一种通用的组合算法，可以将各种分类算法进行组合。
  * 提升树
    * 以分类树或回归树为基本分类器的提升方法（组合算法）
    * 提升树是统计学习中性能最好的方法之一
  * Bagging 算法（本章无介绍，了解请参考、[周志华，2018] C8.3）
    * 随机森林
* AdaBoost 算法
  * 模型：加法模型
    * 如何改变训练数据的权值和概率分布：采用 “分而治之” 的方法。提高那些被前一轮弱分类器错误分类的样本的权值，从而保证后一轮的弱分类器在学习过程中能够更多关注它们。
    * 如何将弱分类器组合成一个强分类器：采用 “加权多数表决” 的方法。加大分类误差率小的弱分类器的权值，从而保证它们在表决中起较大的作用。
  * 策略：指数损失函数极小化，即经验风险极小化。
  * 算法：前向分步算法来优化分步优化指数损失函数的极小化问题。
  * 算法的训练误差分析
    * AdaBoost能够在学习过程中不断减少训练误差，即减少训练数据集上的分类误差率。
      * AdaBoost的训练误差是以指数速率下降的。_定理与证明可以略过_
  * 算法的优化过程分析
    * 因为学习的是加法模型，所以能够从前向后，每一步只学习一个基函数及基系数，逐步逼近优化目标函数，简化优化的复杂度。
    * _前向分步算法与AdaBoost的关系：定理与证明可以略过。_
* 提升树模型
  * 模型：加法模型，以决策树为基函数
  * 策略：损失函数
    * 分类问题：指数损失函数
    * 回归问题：平方误差函数
    * 一般决策问题：一般损失函数
  * 算法：前向分步算法
    * 梯度提升算法（GBDT）：解决离散数据的优化问题，原理参考\[Friedman, 2001]
* **学习总结**
  * 学习基础
    * 熟悉重要的分类算法：神经网络和支持向量机
    * 熟悉常用的分类算法：k 近邻法和决策树
  * 学习目标
    * 组合各种分类算法，从而产生质量更好的学习能力和泛化能力模型
  * 胡思乱想
    * 全连接的深度神经网络就是理论上最完美的组合模型，问题在于维度灾难带来的计算复杂度问题。
    * 为了解决计算复杂度问题，就需要了解其他分类模型，因为其他分类模型就是具备了先验知识的神经网络模型，将那些分类模型转化为神经网络模型后就可以大幅减少连接的数量。
    * 概率近似正确 (probably approximately correct, PAC) 来自于计算学习理论，可参考、[周志华，2018] C12, \[Mitchell, 2003] C07
    * 集成学习 (ensemble learning) 也被称为多分类器系统、基于委员会的学习等，可参考、[周志华，2018] C08

# C09. EM算法及推广

* 学习基础
  * 概率论：期望
  * 最大似然估计或极大后验估计
  * 梯度下降
* EM算法是对含有隐变量的概率模型进行极大似然估计或者极大后验估计的迭代算法。
  * E步，求期望；利用数据和假设的初值，求得一个隐变量的条件概率分布的期望，即 “Q 函数”。（因为无法求得条件概率分布的具体值）
  * M步，求极值。利用 “Q 函数” 来求极值，这个极值可以帮助拟合的概率分布更加逼近真实分布。
  * **Q函数的定义**（理解Q函数的涵义可以更好地推广到应用中，开始不理解也没关系，可以在应用中慢慢加深）
  * **EM算法的推导**（如果书上的无法理解，还可以参考本文中的其他文献）
    * EM算法是收敛的，但是有可能收敛到局部最小值。
    * EM算法可以看成利用凸函数进行概率密度逼近；
    * 如果原概率密度函数有多个极值，初值的不同就可能逼近到不同的极值点，所以无法保证全局最优。
  * EM算法的应用（下面的两个应用都是重点，但是无法从本书中完全理解，可以在未来的应用继续探索）
    * **高斯混合模型**
    * **HMM（隐Markov模型）**
  * _EM算法的推广_（建议跳过，对了解EM算法帮助不大，只有深入理解和研究EM算法才需要）
    * F函数的极大-极大算法
    * 广义EM算法（GEM）
* **学习总结**
* EM算法的详细推导。\[Borman, 2004], 或者Determined22的[EM算法简述及简单示例（三硬币模型）](http://www.cnblogs.com/Determined22/p/5776791.html)
* EM算法的概率分析。\[Friedman, 2001], 或者苏剑林的[梯度下降和EM算法](https://spaces.ac.cn/archives/4277)
* EM算法的深入理解。可以参考史春奇的[Hinton和Jordan理解的EM算法](https://www.jianshu.com/p/bfa6b5947cd9)

# 参考文献

* \[Duda, 2003] Duda R O, Peter E Hart, etc. 李宏东等译。模式分类 \[M]. 机械工业出版社。2003.
* \[Friedman, 2001] Friedman, Jerome H. “Greedy Function Approximation: A Gradient Boosting Machine.” Annals of Statistics, vol. 29, no. 5, 2001, pp. 1189–1232.
* \[Goodfellow, 2017] Goodfellow I, Bengio Y, Courville A. 深度学习 \[M]. 人民邮电出版社。2017.
* \[Hagan, 2006] Martin T. Hagan. 戴葵等译。神经网络设计、[M]. 2002.
* \[Haykin, 2011] Haykin S . 神经网络与机器学习 \[M]. 机械工业出版社。2011.
* \[Hyvarinen, 2007] Aapo Hyvarinen, Juha Karhunen. 周宗潭译 独立成分分析 \[M]. 电子工业出版社。2007.
* \[Mitchell, 2003] Tom M.Mitchell. 肖华军等译。机器学习 \[M]. 机械工业出版社。2003
* \[Rabiner, 1989] Rabiner L R. A tutorial on hidden Markov models and selected applications in speech recognition \[J]. Proceedings of the IEEE, 1989, 77(2): 257-286.
* \[周志华，2018] 周志华 机器学习 \[M]. 清华大学出版社。2018
* \[Borman, 2004] Borman S. The expectation maximization algorithm-a short tutorial[J]. Submitted for publication, 2004, 41.
* \[Determined22, 2017] Determined22, http://www.cnblogs.com/Determined22/p/5776791.html , 2017.
* \[苏剑林, 2017] 苏剑林, https://spaces.ac.cn/archives/4277 , 2017.
* \[Friedman, 2001] Friedman J, Hastie T, Tibshirani R. The elements of statistical learning[M]. New York: Springer series in statistics, 2001.

# 符号说明

* Pxx，代表第 xx 页；
* Cxx，代表第 xx 章；
* \[M]，代表图书；
* \[J]，代表杂志；